#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WARNING ‚Äî FICHIER BACKUP OBSOL√àTE
==================================
Ce fichier est un backup historique qui utilise FFmpeg LOCAL pour la conversion audio.
Cela viole la CONTRAINTE #10 du CLAUDE.md qui exige l'utilisation de CloudConvert API
pour la compatibilit√© serveur distant.

NE PAS UTILISER ce fichier en production.
Utiliser √† la place : implementation/reception_preparation.py (version principale)
qui utilise CloudConvert API (implementation/audio_converter_api.py).

Ce fichier est conserv√© uniquement comme r√©f√©rence historique.
==================================

Workflow: R√©ception et Pr√©paration de Demande de Transcription CISR
Framework: "ii" (Information/Impl√©mentation)

LIRE: instruction/reception_preparation.md AVANT d'ex√©cuter ce script.

Ce workflow impl√©mente la phase initiale de r√©ception d'une demande de transcription,
extraction des m√©tadonn√©es, validation et g√©n√©ration du rapport initial.
"""

import os
import sys
import json
import argparse
import logging
import re
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# Fix encoding Windows
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')

# Configurer FFmpeg portable
try:
    ffmpeg_config_path = Path(__file__).parent.parent / 'ffmpeg_config.py'
    if ffmpeg_config_path.exists():
        import importlib.util
        spec = importlib.util.spec_from_file_location("ffmpeg_config", ffmpeg_config_path)
        ffmpeg_config = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(ffmpeg_config)
except Exception:
    pass  # FFmpeg config optionnel

# Ajouter le r√©pertoire .claudecode/skills au path pour importer le skill CISR
skill_path = Path(__file__).parent.parent / '.claudecode' / 'skills'
sys.path.insert(0, str(skill_path))

try:
    from cisr_transcription_assistant import CISRTranscriptionAssistant
except ImportError as e:
    print(f"‚ùå ERREUR: Impossible d'importer CISRTranscriptionAssistant")
    print(f"   Chemin recherch√©: {skill_path}")
    print(f"   Erreur: {e}")
    sys.exit(1)


# Configuration logging
def setup_logging(demande_folder: Path) -> logging.Logger:
    """Configure le logging pour ce workflow."""
    log_dir = demande_folder / 'logs'
    log_dir.mkdir(exist_ok=True)

    log_file = log_dir / f'reception_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )

    return logging.getLogger(__name__)


def decouper_audio_selon_remarks(audio_file: Path, metadata_work_order: Dict, logger: logging.Logger) -> Optional[Path]:
    """
    D√©coupe le fichier audio selon les Recording Unit Remarks du Work Order Excel.

    Cette fonction lit les instructions de d√©coupage depuis metadata_work_order.json
    (enrichi par Workflow 0) et utilise FFmpeg pour cr√©er une version d√©coup√©e du fichier audio.

    Args:
        audio_file: Chemin vers le fichier audio original
        metadata_work_order: Dict m√©tadonn√©es depuis metadata_work_order.json
        logger: Logger pour journalisation

    Returns:
        Path vers fichier audio d√©coup√© si d√©coupage appliqu√©, None sinon

    Exemples Recording Remarks:
        - "commence √† 1:33" ‚Üí Commence √† 1 minute 33 secondes
        - "commence √† 0:46" ‚Üí Commence √† 46 secondes
        - "arr√™te √† 8:30" ‚Üí Arr√™te √† 8 minutes 30 secondes

    Raises:
        subprocess.CalledProcessError: Si FFmpeg √©choue
        FileNotFoundError: Si FFmpeg n'est pas install√©
    """
    # V√©rifier si m√©tadonn√©es transcription disponibles
    if 'transcription' not in metadata_work_order:
        logger.info("   ‚ÑπÔ∏è  Aucune m√©tadonn√©e transcription (Excel) - d√©coupage ignor√©")
        return None

    transcription_meta = metadata_work_order['transcription']
    recording_remarks = transcription_meta.get('recording_remarks')

    if not recording_remarks:
        logger.info("   ‚ÑπÔ∏è  Aucun Recording Remark - d√©coupage ignor√©")
        return None

    # Extraire start_time_seconds (d√©j√† pars√© par workflow 0)
    audio_decoupage = transcription_meta.get('audio_decoupage', {})
    start_seconds = audio_decoupage.get('start_time_seconds')

    if not start_seconds or start_seconds <= 0:
        logger.info(f"   ‚ÑπÔ∏è  Recording Remark pr√©sent mais aucun d√©coupage d√©tect√©: '{recording_remarks}'")
        return None

    # === D√âCOUPAGE AUDIO AVEC FFMPEG ===
    logger.info(f"   üéØ D√©coupage audio d√©tect√©: '{recording_remarks}'")
    logger.info(f"      D√©marrer √†: {start_seconds}s ({start_seconds//60}:{start_seconds%60:02d})")

    # G√©n√©rer nom fichier de sortie
    output_file = audio_file.parent / f"{audio_file.stem}_trimmed{audio_file.suffix}"

    # Commande FFmpeg
    # -i input.wav : Fichier d'entr√©e
    # -ss {seconds} : D√©marrer √† X secondes
    # -c copy : Copier codec (pas de r√©encodage, tr√®s rapide)
    # output_trimmed.wav : Fichier de sortie
    cmd = [
        'ffmpeg',
        '-i', str(audio_file),
        '-ss', str(start_seconds),
        '-c', 'copy',
        '-y',  # Overwrite sans demander
        str(output_file)
    ]

    try:
        logger.info(f"   üîß Ex√©cution FFmpeg...")
        result = subprocess.run(
            cmd,
            check=True,
            capture_output=True,
            text=True
        )

        # V√©rifier que fichier cr√©√©
        if output_file.exists():
            original_size = audio_file.stat().st_size / (1024 * 1024)  # MB
            trimmed_size = output_file.stat().st_size / (1024 * 1024)  # MB
            economies = original_size - trimmed_size

            logger.info(f"   ‚úÖ Audio d√©coup√© avec succ√®s:")
            logger.info(f"      Fichier original: {original_size:.2f} MB")
            logger.info(f"      Fichier d√©coup√©: {trimmed_size:.2f} MB")
            logger.info(f"      √âconomie: {economies:.2f} MB ({economies/original_size*100:.1f}%)")
            logger.info(f"      üìÅ {output_file.name}")

            return output_file
        else:
            logger.error(f"   ‚ùå FFmpeg termin√© mais fichier non cr√©√©: {output_file}")
            return None

    except FileNotFoundError:
        logger.error("   ‚ùå FFmpeg non trouv√© - installation requise")
        logger.error("      Windows: choco install ffmpeg")
        logger.error("      Mac: brew install ffmpeg")
        logger.error("      Linux: sudo apt-get install ffmpeg")
        return None

    except subprocess.CalledProcessError as e:
        logger.error(f"   ‚ùå Erreur FFmpeg: {e}")
        logger.error(f"      stderr: {e.stderr}")
        return None


class ReceptionPreparationWorkflow:
    """Workflow de r√©ception et pr√©paration de demande de transcription CISR."""

    def __init__(self, demande_folder: Path, section: Optional[str] = None,
                 email_notification: bool = False, metadata_json_path: Optional[str] = None):
        """
        Initialise le workflow.

        Args:
            demande_folder: Chemin vers le dossier contenant page couverture + audio
            section: Type de section CISR (SPR, SAR, SI, SAI) - optionnel, auto-d√©tect√©
            email_notification: Activer les notifications email
            metadata_json_path: Chemin vers metadata_work_order.json (workflow 0)
        """
        self.demande_folder = Path(demande_folder)
        self.section = section
        self.email_notification = email_notification
        self.metadata_json_path = metadata_json_path
        self.logger = setup_logging(self.demande_folder)
        self.assistant = CISRTranscriptionAssistant()

        # R√©sultats du workflow
        self.metadata = {}
        self.divergences = []
        self.audio_info = {}

        # Pr√©-charger m√©tadonn√©es depuis workflow 0 si disponible
        if self.metadata_json_path and Path(self.metadata_json_path).exists():
            self._load_metadata_from_workflow0()

    def _load_metadata_from_workflow0(self) -> None:
        """
        Charge les m√©tadonn√©es depuis metadata_work_order.json g√©n√©r√© par workflow 0.

        Format attendu:
        {
          "dossier": {"numero": "TC5-07390", "section": "SPR", "iuc": "1118522122", ...},
          "participants": {"demandeur": "...", "commissaire": "...", ...},
          "audience": {"date": "23 octobre 2025", "lieu": "...", ...}
        }
        """
        try:
            with open(self.metadata_json_path, 'r', encoding='utf-8') as f:
                metadata_wo = json.load(f)

            # Mapper format workflow 0 ‚Üí format workflow 1
            self.metadata = {
                'section_type': metadata_wo.get('dossier', {}).get('section', 'SPR'),
                'numero_dossier': metadata_wo.get('dossier', {}).get('numero'),
                'date_audience': metadata_wo.get('audience', {}).get('date'),
                'heure_debut': metadata_wo.get('audience', {}).get('heure_debut', 'N/A'),
                'heure_fin': metadata_wo.get('audience', {}).get('heure_fin', 'N/A'),
                'lieu_audience': metadata_wo.get('audience', {}).get('lieu'),
                'date_decision': metadata_wo.get('audience', {}).get('date_decision'),
                'iuc': metadata_wo.get('dossier', {}).get('iuc'),
                'huis_clos': metadata_wo.get('dossier', {}).get('huis_clos', False),
                'participants': [
                    metadata_wo.get('participants', {}).get('demandeur'),
                    metadata_wo.get('participants', {}).get('commissaire'),
                    metadata_wo.get('participants', {}).get('conseil_demandeur'),
                    metadata_wo.get('participants', {}).get('interprete')
                ],
                'metadata_work_order_original': metadata_wo  # Conserver original
            }

            # Auto-d√©tecter section si non fournie
            if not self.section:
                self.section = self.metadata['section_type']

            self.logger.info(f"‚úÖ M√©tadonn√©es pr√©-charg√©es depuis workflow 0 : {self.metadata_json_path}")
            self.logger.info(f"   Section: {self.metadata['section_type']}")
            self.logger.info(f"   Dossier: {self.metadata['numero_dossier']}")
            self.logger.info(f"   Demandeur: {metadata_wo.get('participants', {}).get('demandeur')}")

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è  Impossible de charger metadata_work_order.json: {e}")
            self.logger.warning("   Extraction depuis page couverture sera utilis√©e")

    def step1_reception_demande(self) -> bool:
        """
        √âtape 1: R√©ception de la demande.
        V√©rifie l'existence du dossier et des fichiers requis.

        Returns:
            True si succ√®s, False sinon
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 1/6: R√©ception de la demande")
        self.logger.info("=" * 60)

        # V√©rifier existence dossier
        if not self.demande_folder.exists():
            self.logger.error(f"‚ùå Dossier introuvable: {self.demande_folder}")
            return False

        self.logger.info(f"‚úÖ Dossier trouv√©: {self.demande_folder}")

        # Lister les fichiers
        fichiers = list(self.demande_folder.glob('*'))
        self.logger.info(f"üìÅ Fichiers trouv√©s: {len(fichiers)}")

        # Rechercher page couverture DOCX
        docx_files = list(self.demande_folder.glob('*.docx'))
        if not docx_files:
            self.logger.error("‚ùå Aucun fichier DOCX (page couverture) trouv√©")
            return False

        self.metadata['page_couverture_path'] = str(docx_files[0])
        self.logger.info(f"‚úÖ Page couverture: {docx_files[0].name}")

        # Rechercher fichiers audio
        audio_extensions = ['.mp3', '.wav', '.m4a', '.flac', '.ogg']
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(self.demande_folder.glob(f'*{ext}'))

        if not audio_files:
            self.logger.error("‚ùå Aucun fichier audio trouv√©")
            return False

        self.metadata['audio_files'] = [str(f) for f in audio_files]
        self.logger.info(f"‚úÖ Fichiers audio trouv√©s: {len(audio_files)}")
        for audio in audio_files:
            self.logger.info(f"   - {audio.name}")

        return True

    def step2_extraction_page_couverture(self) -> bool:
        """
        √âtape 2: Extraction m√©tadonn√©es page couverture.
        Utilise le skill CISR pour extraire les informations.

        Returns:
            True si succ√®s, False sinon
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 2/6: Extraction page couverture")
        self.logger.info("=" * 60)

        # Si m√©tadonn√©es d√©j√† charg√©es depuis workflow 0, skip extraction
        if self.metadata.get('metadata_work_order_original'):
            self.logger.info("Skip - M√©tadonn√©es d√©j√† charg√©es depuis workflow 0")
            self.logger.info(f"   Section: {self.metadata.get('section_type', 'N/A')}")
            self.logger.info(f"   Num√©ro dossier: {self.metadata.get('numero_dossier', 'N/A')}")
            self.logger.info(f"   Date audience: {self.metadata.get('date_audience', 'N/A')}")
            return True

        try:
            page_data = self.assistant.extract_page_couverture(
                self.metadata['page_couverture_path']
            )

            # Fusionner avec metadata (seulement si pas d√©j√† depuis workflow 0)
            self.metadata.update(page_data)

            self.logger.info("‚úÖ M√©tadonn√©es extraites:")
            self.logger.info(f"   Section: {page_data.get('section_type', 'N/A')}")
            self.logger.info(f"   Num√©ro dossier: {page_data.get('numero_dossier', 'N/A')}")
            self.logger.info(f"   Date audience: {page_data.get('date_audience', 'N/A')}")
            self.logger.info(f"   Heure d√©but: {page_data.get('heure_debut', 'N/A')}")
            self.logger.info(f"   Heure fin: {page_data.get('heure_fin', 'N/A')}")
            self.logger.info(f"   Participants: {', '.join(page_data.get('participants', []))}")

            # Auto-d√©tection section si non fournie
            if not self.section and 'section_type' in page_data:
                self.section = page_data['section_type']
                self.logger.info(f"üîç Section auto-d√©tect√©e: {self.section}")

            return True

        except Exception as e:
            self.logger.error(f"‚ùå Erreur extraction page couverture: {e}")
            return False

    def step3_validation_metadata(self) -> bool:
        """
        √âtape 3: Validation des m√©tadonn√©es extraites.
        V√©rifie le format, notamment pour SAR (double num√©ro).

        Returns:
            True si succ√®s, False sinon
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 3/6: Validation m√©tadonn√©es")
        self.logger.info("=" * 60)

        erreurs = []

        # V√©rifier champs obligatoires
        champs_requis = ['section_type', 'numero_dossier']

        for champ in champs_requis:
            if champ not in self.metadata or not self.metadata[champ]:
                erreurs.append(f"Champ obligatoire manquant: {champ}")

        # V√©rification sp√©cifique SAR: double num√©ro
        if self.metadata.get('section_type') == 'SAR':
            numero = self.metadata.get('numero_dossier', '')
            if '/' not in numero or 'SPR' not in numero or 'SAR' not in numero:
                erreurs.append(
                    "SAR: Double num√©ro requis (format: SPR-XXXXX / SAR-XXXXX)"
                )
                self.logger.warning("‚ö†Ô∏è  SAR Prot√©g√© B: Double num√©ro manquant ou invalide")
            else:
                self.logger.info("‚úÖ SAR: Double num√©ro valid√©")

        # V√©rifier format date
        try:
            if 'date_audience' in self.metadata:
                # Essayer de parser la date (formats accept√©s: YYYY-MM-DD, DD/MM/YYYY)
                date_str = self.metadata['date_audience']
                if date_str:  # V√©rifier que date_str n'est pas None
                    if '-' in date_str:
                        datetime.strptime(date_str, '%Y-%m-%d')
                    elif '/' in date_str:
                        datetime.strptime(date_str, '%d/%m/%Y')
        except ValueError:
            erreurs.append(f"Format date invalide: {self.metadata['date_audience']}")

        # Afficher r√©sultats
        if erreurs:
            self.logger.error(f"‚ùå Validation √©chou√©e: {len(erreurs)} erreur(s)")
            for erreur in erreurs:
                self.logger.error(f"   - {erreur}")
            return False

        self.logger.info("‚úÖ Validation m√©tadonn√©es r√©ussie")
        return True

    def step3_5_decoupage_audio(self) -> bool:
        """
        √âtape 3.5: D√©coupage audio selon Recording Unit Remarks (NOUVEAU - Sprint 0.2).

        Cette √©tape lit les instructions de d√©coupage depuis metadata_work_order.json
        (enrichi par Workflow 0) et d√©coupe les fichiers audio AVANT analyse/transcription.

        Returns:
            True si succ√®s (d√©coupage appliqu√© ou ignor√©), False si erreur critique
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 3.5/7: D√©coupage audio (Recording Remarks)")
        self.logger.info("=" * 60)

        # V√©rifier si metadata_work_order.json disponible
        if not self.metadata_json_path or not Path(self.metadata_json_path).exists():
            self.logger.info("   ‚ÑπÔ∏è  Aucun metadata_work_order.json - d√©coupage ignor√©")
            self.logger.info("      (Ex√©cuter Workflow 0 en premier pour b√©n√©ficier du d√©coupage)")
            return True

        # Charger metadata_work_order.json
        try:
            with open(self.metadata_json_path, 'r', encoding='utf-8') as f:
                metadata_wo = json.load(f)
        except Exception as e:
            self.logger.warning(f"   ‚ö†Ô∏è  Erreur lecture metadata_work_order.json: {e}")
            self.logger.warning("      D√©coupage ignor√©")
            return True

        # V√©rifier qu'il y a des fichiers audio
        if 'audio_files' not in self.metadata or not self.metadata['audio_files']:
            self.logger.warning("   ‚ö†Ô∏è  Aucun fichier audio trouv√© - d√©coupage ignor√©")
            return True

        # D√©couper chaque fichier audio (g√©n√©ralement 1 seul, mais peut √™tre multiple)
        audio_files = [Path(f) for f in self.metadata['audio_files']]
        fichiers_decoupe = []

        for audio_file in audio_files:
            self.logger.info(f"\n   üìÅ Traitement: {audio_file.name}")

            # Appeler fonction de d√©coupage
            audio_trimmed = decouper_audio_selon_remarks(audio_file, metadata_wo, self.logger)

            if audio_trimmed:
                fichiers_decoupe.append(str(audio_trimmed))
            else:
                # Pas de d√©coupage appliqu√©, garder fichier original
                fichiers_decoupe.append(str(audio_file))

        # Mettre √† jour la liste des fichiers audio dans metadata
        if fichiers_decoupe:
            self.metadata['audio_files'] = fichiers_decoupe
            self.logger.info(f"\n   ‚úÖ √âtape d√©coupage audio termin√©e")
            self.logger.info(f"      {len(fichiers_decoupe)} fichier(s) pr√™t(s) pour analyse")
        else:
            self.logger.info(f"\n   ‚ÑπÔ∏è  Aucun fichier audio disponible apr√®s d√©coupage")

        return True

    def step4_analyse_audio(self) -> bool:
        """
        √âtape 4: Analyse pr√©liminaire des fichiers audio.
        V√©rifie dur√©e, qualit√©, nombre de fichiers.

        Returns:
            True si succ√®s, False sinon
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 4/6: Analyse audio pr√©liminaire")
        self.logger.info("=" * 60)

        try:
            from pydub import AudioSegment
            from pydub.utils import mediainfo
        except ImportError:
            self.logger.warning("‚ö†Ô∏è  pydub non install√© - analyse audio limit√©e")
            self.logger.warning("   Installation: pip install pydub")
            # Continuer sans analyse d√©taill√©e
            self.audio_info = {
                'nombre_fichiers': len(self.metadata['audio_files']),
                'analyse_complete': False
            }
            return True

        audio_files = [Path(f) for f in self.metadata['audio_files']]
        total_duration = 0
        fichiers_info = []

        for audio_file in audio_files:
            try:
                # Charger audio
                audio = AudioSegment.from_file(str(audio_file))
                duration = len(audio) / 1000.0  # Convertir ms ‚Üí secondes
                total_duration += duration

                # Informations d√©taill√©es
                info = mediainfo(str(audio_file))

                fichier_info = {
                    'nom': audio_file.name,
                    'duree_secondes': duration,
                    'duree_formatee': self._format_duration(duration),
                    'sample_rate': info.get('sample_rate', 'N/A'),
                    'channels': info.get('channels', 'N/A'),
                    'format': audio_file.suffix[1:].upper()
                }

                fichiers_info.append(fichier_info)

                self.logger.info(f"üìä {audio_file.name}:")
                self.logger.info(f"   Dur√©e: {fichier_info['duree_formatee']}")
                self.logger.info(f"   Format: {fichier_info['format']}")
                self.logger.info(f"   Sample rate: {fichier_info['sample_rate']}")
                self.logger.info(f"   Channels: {fichier_info['channels']}")

            except Exception as e:
                self.logger.error(f"‚ùå Erreur analyse {audio_file.name}: {e}")
                return False

        self.audio_info = {
            'nombre_fichiers': len(audio_files),
            'duree_totale_secondes': total_duration,
            'duree_totale_formatee': self._format_duration(total_duration),
            'fichiers': fichiers_info,
            'analyse_complete': True
        }

        self.logger.info("‚úÖ Analyse audio termin√©e")
        self.logger.info(f"üìä Dur√©e totale: {self.audio_info['duree_totale_formatee']}")

        return True

    def step5_validation_croisee(self) -> bool:
        """
        √âtape 5: Validation crois√©e page couverture ‚Üî audio.
        CRITIQUE: D√©tecte divergences et envoie email imm√©diat si n√©cessaire.

        Returns:
            True si succ√®s (m√™me avec divergences), False si erreur technique
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 5/6: Validation crois√©e page ‚Üî audio")
        self.logger.info("=" * 60)

        try:
            # Pr√©parer m√©tadonn√©es audio pour validation
            audio_metadata = {
                'duree_totale': self.audio_info.get('duree_totale_secondes', 0),
                'nombre_fichiers': self.audio_info.get('nombre_fichiers', 0)
            }

            # Validation via skill CISR
            validation = self.assistant.validate_page_couverture(
                self.metadata,
                audio_metadata
            )

            self.divergences = validation.get('divergences', [])
            actions_requises = validation.get('actions_requises', [])

            if validation['valide']:
                self.logger.info("‚úÖ Validation crois√©e: AUCUNE divergence")
                return True

            # Divergences d√©tect√©es
            self.logger.warning(f"‚ö†Ô∏è  DIVERGENCES D√âTECT√âES: {len(self.divergences)}")
            for div in self.divergences:
                self.logger.warning(f"   - {div}")

            # Actions requises (emails, etc.)
            if actions_requises:
                self.logger.warning(f"üö® ACTIONS REQUISES: {len(actions_requises)}")
                for action in actions_requises:
                    self.logger.warning(f"   - {action}")

                # Envoyer email si notification activ√©e
                if self.email_notification:
                    self._send_divergence_email(validation)

            # Sauvegarder divergences dans fichier JSON
            divergences_file = self.demande_folder / 'divergences.json'
            with open(divergences_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'divergences': self.divergences,
                    'actions_requises': actions_requises,
                    'validation_complete': validation
                }, f, indent=2, ensure_ascii=False)

            self.logger.warning(f"üìÑ Divergences sauvegard√©es: {divergences_file}")

            return True  # Succ√®s technique, m√™me avec divergences

        except Exception as e:
            self.logger.error(f"‚ùå Erreur validation crois√©e: {e}")
            return False

    def step6_generation_rapport(self) -> bool:
        """
        √âtape 6: G√©n√©ration du rapport initial.
        Utilise le skill CISR pour formater le rapport.

        Returns:
            True si succ√®s, False sinon
        """
        self.logger.info("=" * 60)
        self.logger.info("√âTAPE 6/6: G√©n√©ration rapport initial")
        self.logger.info("=" * 60)

        try:
            # G√©n√©rer rapport via skill
            rapport = self.assistant.generate_rapport(
                section_type=self.metadata.get('section_type', 'SPR'),
                numero_dossier=self.metadata.get('numero_dossier', 'N/A')
            )

            # Ajouter informations suppl√©mentaires
            rapport += f"\n\n## M√©tadonn√©es Extraites\n\n"
            rapport += f"- **Date audience**: {self.metadata.get('date_audience', 'N/A')}\n"
            rapport += f"- **Heure**: {self.metadata.get('heure_debut', 'N/A')} √† {self.metadata.get('heure_fin', 'N/A')}\n"
            rapport += f"- **Participants**: {', '.join(self.metadata.get('participants', []))}\n"

            rapport += f"\n## Analyse Audio\n\n"
            rapport += f"- **Nombre de fichiers**: {self.audio_info.get('nombre_fichiers', 'N/A')}\n"
            rapport += f"- **Dur√©e totale**: {self.audio_info.get('duree_totale_formatee', 'N/A')}\n"

            if self.divergences:
                rapport += f"\n## ‚ö†Ô∏è DIVERGENCES D√âTECT√âES\n\n"
                for i, div in enumerate(self.divergences, 1):
                    rapport += f"{i}. {div}\n"
            else:
                rapport += f"\n## ‚úÖ Validation\n\nAucune divergence d√©tect√©e.\n"

            rapport += f"\n---\n\n"
            rapport += f"**G√©n√©r√© le**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            rapport += f"**Workflow**: reception_preparation (Framework \"ii\")\n"

            # Sauvegarder rapport
            rapport_file = self.demande_folder / 'rapport_initial.md'
            with open(rapport_file, 'w', encoding='utf-8') as f:
                f.write(rapport)

            self.logger.info(f"‚úÖ Rapport g√©n√©r√©: {rapport_file}")

            # Sauvegarder m√©tadonn√©es JSON
            metadata_file = self.demande_folder / 'metadata.json'
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'metadata': self.metadata,
                    'audio_info': self.audio_info,
                    'divergences': self.divergences,
                    'timestamp': datetime.now().isoformat()
                }, f, indent=2, ensure_ascii=False)

            self.logger.info(f"‚úÖ M√©tadonn√©es JSON: {metadata_file}")

            return True

        except Exception as e:
            self.logger.error(f"‚ùå Erreur g√©n√©ration rapport: {e}")
            return False

    def _send_divergence_email(self, validation: Dict) -> None:
        """
        Envoie un email de notification de divergences.

        Args:
            validation: R√©sultat de la validation crois√©e
        """
        try:
            dossier_info = {
                'numero_dossier': self.metadata.get('numero_dossier', 'N/A'),
                'section_type': self.metadata.get('section_type', 'N/A'),
                'date_audience': self.metadata.get('date_audience', 'N/A')
            }

            from dotenv import load_dotenv
            load_dotenv()

            destinataires = os.getenv('CISR_EMAIL_TO_UNITE_ENREGISTREMENT', '').split(',')
            cc = os.getenv('CISR_EMAIL_CC', '').split(',')
            destinataires.extend(cc)

            self.assistant.send_divergence_email(
                destinataires=destinataires,
                divergences=validation.get('divergences', []),
                dossier_info=dossier_info
            )

            self.logger.info(f"üìß Email de divergences envoy√© √† {len(destinataires)} destinataire(s)")

        except Exception as e:
            self.logger.error(f"‚ùå Erreur envoi email: {e}")

    def _format_duration(self, seconds: float) -> str:
        """Formate une dur√©e en secondes vers HH:MM:SS."""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)

        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"

    def run(self) -> int:
        """
        Ex√©cute le workflow complet.

        Returns:
            Code de sortie (0 = succ√®s, 1 = erreur)
        """
        self.logger.info("üöÄ D√©marrage workflow: reception_preparation")
        self.logger.info(f"üìÅ Dossier: {self.demande_folder}")
        self.logger.info(f"üìß Notifications email: {'ACTIV√âES' if self.email_notification else 'D√âSACTIV√âES'}")

        start_time = datetime.now()

        # Ex√©cuter les 6 √©tapes
        steps = [
            self.step1_reception_demande,
            self.step2_extraction_page_couverture,
            self.step3_validation_metadata,
            self.step3_5_decoupage_audio,  # NOUVEAU - Sprint 0.2
            self.step4_analyse_audio,
            self.step5_validation_croisee,
            self.step6_generation_rapport
        ]

        for i, step in enumerate(steps, 1):
            if not step():
                self.logger.error(f"‚ùå √âCHEC √† l'√©tape {i}/7")
                self.logger.error(f"‚è±Ô∏è  Dur√©e totale: {datetime.now() - start_time}")
                return 1

        # Succ√®s
        duration = datetime.now() - start_time
        self.logger.info("=" * 60)
        self.logger.info("‚úÖ WORKFLOW TERMIN√â AVEC SUCC√àS")
        self.logger.info("=" * 60)
        self.logger.info(f"‚è±Ô∏è  Dur√©e totale: {duration}")
        self.logger.info(f"üìä Fichiers g√©n√©r√©s:")
        self.logger.info(f"   - {self.demande_folder / 'metadata.json'}")
        self.logger.info(f"   - {self.demande_folder / 'rapport_initial.md'}")
        if self.divergences:
            self.logger.info(f"   - {self.demande_folder / 'divergences.json'}")
            self.logger.warning(f"‚ö†Ô∏è  {len(self.divergences)} divergence(s) d√©tect√©e(s)")

        return 0


def main():
    """Point d'entr√©e CLI."""
    parser = argparse.ArgumentParser(
        description='Workflow: R√©ception et Pr√©paration de Demande de Transcription CISR',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python reception_preparation.py --demande-folder ./dossier_SPR12345
  python reception_preparation.py --demande-folder ./dossier_SAR --section SAR --email-notification

Fichiers requis dans le dossier:
  - Page couverture (*.docx)
  - Fichier(s) audio (*.mp3, *.wav, *.m4a, etc.)

Fichiers g√©n√©r√©s:
  - metadata.json (m√©tadonn√©es extraites)
  - rapport_initial.md (rapport format√©)
  - divergences.json (si divergences d√©tect√©es)
  - logs/reception_YYYYMMDD_HHMMSS.log (journal d'ex√©cution)
        """
    )

    parser.add_argument(
        '--demande-folder',
        required=True,
        help='Chemin vers le dossier contenant page couverture + audio'
    )

    parser.add_argument(
        '--metadata-json',
        help='Fichier metadata_work_order.json (workflow 0) pour pr√©-charger m√©tadonn√©es'
    )

    parser.add_argument(
        '--section',
        choices=['SPR', 'SAR', 'SI', 'SAI'],
        help='Type de section CISR (optionnel, auto-d√©tect√© depuis page couverture ou metadata.json)'
    )

    parser.add_argument(
        '--email-notification',
        action='store_true',
        help='Activer les notifications email en cas de divergences'
    )

    args = parser.parse_args()

    # Cr√©er et ex√©cuter le workflow
    workflow = ReceptionPreparationWorkflow(
        demande_folder=args.demande_folder,
        section=args.section,
        email_notification=args.email_notification,
        metadata_json_path=args.metadata_json
    )

    exit_code = workflow.run()
    sys.exit(exit_code)


if __name__ == '__main__':
    main()
